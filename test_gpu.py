"""
WhisperFlow Desktop - Test GPU
Script de validation de la configuration CUDA/GPU
"""

import sys
from colorama import init, Fore, Style

init()  # Initialise colorama pour Windows


def print_header(text: str):
    """Affiche un en-t√™te format√©"""
    print(f"\n{Fore.CYAN}{'='*50}")
    print(f"  {text}")
    print(f"{'='*50}{Style.RESET_ALL}\n")


def print_success(text: str):
    """Affiche un message de succ√®s"""
    print(f"{Fore.GREEN}‚úì {text}{Style.RESET_ALL}")


def print_error(text: str):
    """Affiche un message d'erreur"""
    print(f"{Fore.RED}‚úó {text}{Style.RESET_ALL}")


def print_info(text: str):
    """Affiche une information"""
    print(f"{Fore.YELLOW}‚Üí {text}{Style.RESET_ALL}")


def test_pytorch():
    """Test l'installation de PyTorch"""
    print_header("Test PyTorch")
    
    try:
        import torch
        print_success(f"PyTorch version: {torch.__version__}")
        return True
    except ImportError as e:
        print_error(f"PyTorch non install√©: {e}")
        return False


def test_cuda():
    """Test la disponibilit√© de CUDA"""
    print_header("Test CUDA")
    
    import torch
    
    if torch.cuda.is_available():
        print_success("CUDA est disponible!")
        print_info(f"Version CUDA: {torch.version.cuda}")
        print_info(f"Nombre de GPU: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print_info(f"GPU {i}: {props.name}")
            print_info(f"  - M√©moire totale: {props.total_memory / 1024**3:.1f} GB")
            print_info(f"  - Compute Capability: {props.major}.{props.minor}")
        
        return True
    else:
        print_error("CUDA n'est pas disponible!")
        print_info("V√©rifiez que les drivers NVIDIA sont install√©s")
        print_info("V√©rifiez que PyTorch CUDA est bien install√©")
        return False


def test_memory_allocation():
    """Test l'allocation m√©moire GPU"""
    print_header("Test Allocation M√©moire GPU")
    
    import torch
    
    try:
        # Alloue un tensor de test sur le GPU
        test_tensor = torch.randn(1000, 1000, device="cuda")
        print_success(f"Allocation r√©ussie: tensor de forme {test_tensor.shape}")
        
        # Lib√®re la m√©moire
        del test_tensor
        torch.cuda.empty_cache()
        
        # Affiche l'√©tat de la m√©moire
        allocated = torch.cuda.memory_allocated() / 1024**2
        reserved = torch.cuda.memory_reserved() / 1024**2
        print_info(f"M√©moire allou√©e: {allocated:.1f} MB")
        print_info(f"M√©moire r√©serv√©e: {reserved:.1f} MB")
        
        return True
    except Exception as e:
        print_error(f"Erreur d'allocation: {e}")
        return False


def test_float16_support():
    """Test le support Float16 (Half Precision)"""
    print_header("Test Float16 (Half Precision)")
    
    import torch
    
    try:
        # Cr√©e un tensor en Float16
        tensor_fp16 = torch.randn(100, 100, dtype=torch.float16, device="cuda")
        
        # Effectue une op√©ration
        result = torch.matmul(tensor_fp16, tensor_fp16.T)
        
        print_success(f"Float16 fonctionne correctement")
        print_info(f"R√©sultat shape: {result.shape}, dtype: {result.dtype}")
        
        del tensor_fp16, result
        torch.cuda.empty_cache()
        
        return True
    except Exception as e:
        print_error(f"Erreur Float16: {e}")
        return False


def test_transformers():
    """Test l'installation de Transformers"""
    print_header("Test Transformers")
    
    try:
        import transformers
        print_success(f"Transformers version: {transformers.__version__}")
        
        from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
        print_success("Imports critiques OK")
        
        return True
    except ImportError as e:
        print_error(f"Transformers non install√©: {e}")
        return False


def test_audio():
    """Test les d√©pendances audio"""
    print_header("Test Audio (SoundDevice)")
    
    try:
        import sounddevice as sd
        print_success(f"SoundDevice version: {sd.__version__}")
        
        # Liste les p√©riph√©riques audio
        devices = sd.query_devices()
        default_input = sd.query_devices(kind='input')
        
        print_info(f"P√©riph√©rique d'entr√©e par d√©faut: {default_input['name']}")
        print_info(f"Fr√©quences support√©es: {default_input['default_samplerate']} Hz")
        
        return True
    except Exception as e:
        print_error(f"Erreur audio: {e}")
        return False


def main():
    """Ex√©cute tous les tests"""
    print(f"\n{Fore.MAGENTA}{'#'*50}")
    print(f"#  WhisperFlow Desktop - Diagnostic GPU")
    print(f"{'#'*50}{Style.RESET_ALL}")
    
    results = []
    
    # Tests s√©quentiels
    results.append(("PyTorch", test_pytorch()))
    
    if results[-1][1]:  # Si PyTorch OK
        results.append(("CUDA", test_cuda()))
        
        if results[-1][1]:  # Si CUDA OK
            results.append(("Allocation M√©moire", test_memory_allocation()))
            results.append(("Float16", test_float16_support()))
    
    results.append(("Transformers", test_transformers()))
    results.append(("Audio", test_audio()))
    
    # R√©sum√©
    print_header("R√âSUM√â")
    
    all_passed = True
    for name, passed in results:
        if passed:
            print_success(f"{name}: OK")
        else:
            print_error(f"{name}: √âCHEC")
            all_passed = False
    
    print()
    if all_passed:
        print(f"{Fore.GREEN}{'='*50}")
        print("  üöÄ SYST√àME PR√äT POUR WHISPERFLOW!")
        print(f"{'='*50}{Style.RESET_ALL}")
        return 0
    else:
        print(f"{Fore.RED}{'='*50}")
        print("  ‚ö†Ô∏è  CERTAINS TESTS ONT √âCHOU√â")
        print("  Corrigez les erreurs avant de lancer l'application")
        print(f"{'='*50}{Style.RESET_ALL}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
