# WhisperFlow Desktop

ğŸ¤ **Application de transcription vocale temps rÃ©el en local**

Transformez votre voix en texte instantanÃ©ment, en toute confidentialitÃ©, sans connexion cloud.

![WhisperFlow](https://img.shields.io/badge/WhisperFlow-v1.0.0-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![CUDA](https://img.shields.io/badge/CUDA-12.1-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## âœ¨ FonctionnalitÃ©s

- ğŸš€ **Ultra-rapide** - Transcription en temps rÃ©el grÃ¢ce Ã  l'accÃ©lÃ©ration GPU
- ğŸ”’ **100% Local** - Aucune donnÃ©e ne quitte votre ordinateur
- ğŸ¯ **PrÃ©cision** - Utilise Whisper Large V3 Turbo d'OpenAI
- ğŸ¹ **Push-to-Talk** - Appuyez sur F2, parlez, relÃ¢chez, c'est transcrit
- ğŸ“‹ **Copie facile** - RÃ©sultat copiÃ© en un clic ou avec F3
- ğŸ¨ **UI Moderne** - Interface flottante minimaliste style macOS

---

## ğŸ–¥ï¸ PrÃ©requis

| Composant | Minimum | RecommandÃ© |
|-----------|---------|------------|
| **GPU** | NVIDIA GTX 1060 (6GB) | RTX 3080+ / RTX 4080 |
| **VRAM** | 6 GB | 12+ GB |
| **RAM** | 8 GB | 16+ GB |
| **OS** | Windows 10 | Windows 11 |
| **Python** | 3.10 | 3.11 |

### Logiciels requis

1. **Python 3.10+** - [TÃ©lÃ©charger](https://python.org)
2. **Drivers NVIDIA rÃ©cents** - [TÃ©lÃ©charger](https://nvidia.com/drivers)
3. **FFmpeg** (optionnel) - [TÃ©lÃ©charger](https://ffmpeg.org)

---

## ğŸš€ Installation

### Installation automatique (recommandÃ©e)

```bash
# 1. Clonez ou tÃ©lÃ©chargez le projet
cd WhisperFlow

# 2. Lancez l'installation
setup.bat
```

Le script `setup.bat` va automatiquement :
- CrÃ©er un environnement virtuel Python
- Installer PyTorch avec support CUDA 12.1
- Installer toutes les dÃ©pendances
- Tester la configuration GPU
- Lancer l'application

### Installation manuelle

```bash
# 1. CrÃ©er l'environnement virtuel
python -m venv .venv
.venv\Scripts\activate

# 2. Installer PyTorch avec CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Tester le GPU
python test_gpu.py

# 5. Lancer l'application
python main.py
```

---

## ğŸ® Utilisation

### Raccourcis clavier

| Touche | Action |
|--------|--------|
| **F2** | Push-to-Talk (maintenir pour parler) |
| **F3** | Copier la transcription |
| **ESC** | Quitter l'application |

### Workflow typique

1. **Lancez** l'application avec `run.bat`
2. **Attendez** le chargement du modÃ¨le (~30s au premier lancement)
3. **Maintenez F2** et parlez dans votre micro
4. **RelÃ¢chez F2** - la transcription apparaÃ®t instantanÃ©ment
5. **Appuyez F3** pour copier ou cliquez sur "Copier"

---

## âš™ï¸ Configuration

Modifiez `config.py` pour personnaliser :

```python
# Langue de transcription
LANGUAGE = "fr"  # fr, en, es, de, etc.

# Touche Push-to-Talk
PUSH_TO_TALK_KEY = "f2"

# ModÃ¨le Whisper
MODEL_ID = "openai/whisper-large-v3-turbo"
```

### ModÃ¨les disponibles

| ModÃ¨le | VRAM | PrÃ©cision | Vitesse |
|--------|------|-----------|---------|
| `whisper-tiny` | ~1 GB | â­â­ | â­â­â­â­â­ |
| `whisper-base` | ~1 GB | â­â­â­ | â­â­â­â­ |
| `whisper-small` | ~2 GB | â­â­â­â­ | â­â­â­ |
| `whisper-medium` | ~5 GB | â­â­â­â­ | â­â­ |
| `whisper-large-v3` | ~10 GB | â­â­â­â­â­ | â­ |
| **`whisper-large-v3-turbo`** | ~6 GB | â­â­â­â­â­ | â­â­â­ |

---

## ğŸ—ï¸ Architecture

```
WhisperFlow/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e
â”œâ”€â”€ config.py               # Configuration centralisÃ©e
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ setup.bat               # Script d'installation
â”œâ”€â”€ run.bat                 # Lanceur rapide
â”œâ”€â”€ test_gpu.py             # Diagnostic GPU
â”œâ”€â”€ LICENSE                 # Licence MIT
â””â”€â”€ src/
    â”œâ”€â”€ audio_engine.py           # Capture audio (SoundDevice)
    â”œâ”€â”€ transcription_service.py  # Moteur IA (Faster-Whisper)
    â”œâ”€â”€ smart_formatter.py        # Formatage intelligent du texte
    â”œâ”€â”€ ui/
    â”‚   â”œâ”€â”€ main_window.py        # FenÃªtre PyQt6
    â”‚   â”œâ”€â”€ key_capture_dialog.py # Configuration des raccourcis
    â”‚   â”œâ”€â”€ styles.py             # Styles CSS
    â”‚   â””â”€â”€ workers.py            # Threading QThread
    â””â”€â”€ utils/
        â”œâ”€â”€ clipboard.py          # Presse-papier & frappe auto
        â”œâ”€â”€ history.py            # Historique des transcriptions
        â”œâ”€â”€ hotkey_listener.py    # Raccourcis globaux
        â””â”€â”€ settings.py           # Persistance des paramÃ¨tres
```

---

## ğŸ› DÃ©pannage

### "CUDA n'est pas disponible"

1. VÃ©rifiez que vous avez une carte NVIDIA
2. Mettez Ã  jour vos drivers : [nvidia.com/drivers](https://nvidia.com/drivers)
3. RÃ©installez PyTorch : `pip install torch --index-url https://download.pytorch.org/whl/cu121`

### "Out of Memory" (VRAM insuffisante)

1. Fermez les autres applications utilisant le GPU
2. Utilisez un modÃ¨le plus petit dans `config.py` :
   ```python
   MODEL_ID = "openai/whisper-small"
   ```

### Le micro ne fonctionne pas

1. VÃ©rifiez que le micro est autorisÃ© dans Windows
2. Testez avec `python -c "import sounddevice; print(sounddevice.query_devices())"`
3. SÃ©lectionnez manuellement le pÃ©riphÃ©rique dans `config.py`

### L'application ne dÃ©marre pas

1. Lancez `python test_gpu.py` pour diagnostiquer
2. VÃ©rifiez les logs dans le terminal
3. RÃ©installez avec `setup.bat`

---

## ğŸ“Š Performances

TestÃ© sur RTX 4080 (16 GB VRAM) :

| DurÃ©e audio | Temps transcription | RTF* |
|-------------|---------------------|------|
| 5 secondes | ~0.5s | 0.1x |
| 30 secondes | ~2s | 0.07x |
| 1 minute | ~3s | 0.05x |

*RTF (Real-Time Factor) : < 1 = plus rapide que temps rÃ©el

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- ğŸ› Signaler des bugs
- ğŸ’¡ Proposer des fonctionnalitÃ©s
- ğŸ”§ Soumettre des pull requests

---

## ğŸ“„ Licence

MIT License - Libre d'utilisation personnelle et commerciale.

---

## ğŸ™ CrÃ©dits

- [Faster-Whisper](https://github.com/SYSTRAN/faster-whisper) - Moteur de transcription optimisÃ©
- [OpenAI Whisper](https://github.com/openai/whisper) - ModÃ¨le de transcription
- [Hugging Face Transformers](https://huggingface.co/transformers) - Pipeline ML
- [PyQt6](https://riverbankcomputing.com/software/pyqt) - Interface graphique
- [pynput](https://github.com/moses-palmer/pynput) - Raccourcis clavier
- [SoundDevice](https://python-sounddevice.readthedocs.io) - Capture audio

---

<div align="center">

**WhisperFlow Desktop** - Fait avec â¤ï¸ pour la productivitÃ©

</div>
